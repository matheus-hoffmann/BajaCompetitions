{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RepeatedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, max_error, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Leitura do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirar linhas com valores vazios (Em 2013 só tem pontos do enduro e totais)\n",
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pontuação da prova de segurança englobava outras provas até 2014\n",
    "df = df.drop(df[df['Ano'] < 2014].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otimizando a alocação de espaço das colunas numéricas\n",
    "df[\"Ano\"] = pd.to_numeric(df[\"Ano\"], downcast='integer')\n",
    "df[\"Numero\"] = pd.to_numeric(df[\"Numero\"], downcast='integer')\n",
    "df[\"Numero\"] = pd.to_numeric(df[\"Numero\"], downcast='float')\n",
    "df[\"Seguranca\"] = pd.to_numeric(df[\"Seguranca\"], downcast='float')\n",
    "df[\"Dinamicas\"] = pd.to_numeric(df[\"Dinamicas\"], downcast='float')\n",
    "df[\"Enduro\"] = pd.to_numeric(df[\"Enduro\"], downcast='float')\n",
    "df[\"Total\"] = pd.to_numeric(df[\"Total\"], downcast='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Criação do modelo de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Definição das variáveis do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_analisadas = ['Seguranca', 'Projeto', 'Dinamicas', 'Enduro']\n",
    "x = df[variaveis_analisadas]\n",
    "y = df['Posicao']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Normalização dos inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmath\\AppData\\Local\\Temp\\ipykernel_17432\\4091827902.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[variavel] = mms.fit_transform(x[variavel].values.reshape((-1, 1)))\n",
      "C:\\Users\\mmath\\AppData\\Local\\Temp\\ipykernel_17432\\4091827902.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[variavel] = mms.fit_transform(x[variavel].values.reshape((-1, 1)))\n",
      "C:\\Users\\mmath\\AppData\\Local\\Temp\\ipykernel_17432\\4091827902.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[variavel] = mms.fit_transform(x[variavel].values.reshape((-1, 1)))\n",
      "C:\\Users\\mmath\\AppData\\Local\\Temp\\ipykernel_17432\\4091827902.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[variavel] = mms.fit_transform(x[variavel].values.reshape((-1, 1)))\n"
     ]
    }
   ],
   "source": [
    "mms = MinMaxScaler()\n",
    "for variavel in variaveis_analisadas:\n",
    "    x[variavel] = mms.fit_transform(x[variavel].values.reshape((-1, 1)))\n",
    "    pickle.dump(mms, open(\"persistence/mms_{}.pkl\".format(variavel), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Separação do dataset em conjuntos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x.values, y.values, test_size=0.1, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Tuning dos hiper-parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o modelo regressivo e o range de hiper-parâmetros viáveis\n",
    "model = SVR()\n",
    "params = {'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "          'gamma': [0.00001 * pow(10, x) for x in range(10)],\n",
    "          'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 20000, 30000, 40000, 50000, 100000],\n",
    "          'epsilon': [0.01 * pow(10, x) for x in range(3)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a técnica de validação cruzada a ser utilizada. Nesse caso será utilizada a Repeated K-Fold Cross-Validation.\n",
    "cv = RepeatedKFold(n_splits=5,\n",
    "                   n_repeats=1,\n",
    "                   random_state=random_state)\n",
    "\n",
    "# Definindo o tipo de busca que será realizada. Nesse caso será utilizada uma busca randômica pelas combinações de hiper-parâmetros.\n",
    "search = RandomizedSearchCV(estimator=model,\n",
    "                            param_distributions=params,\n",
    "                            cv=cv,\n",
    "                            n_iter=100,\n",
    "                            random_state=random_state,\n",
    "                            scoring='max_error')\n",
    "\n",
    "# Busca dos hiper-parâmetros a partir do grupo de treinamento.\n",
    "search.fit(xtrain, ytrain)\n",
    "\n",
    "# Atualizando o modelo com a melhor combinação de hiper-parâmetros encontrada.\n",
    "model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Treinamento final do modelo de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xtrain, ytrain)\n",
    "pickle.dump(model, open(\"persistence/model.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Predição do grupo de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = np.ceil(model.predict(xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Avaliação do modelo de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score                         :  0.95\n",
      "max_error                        : 11.00\n",
      "mean_absolute_error              :  3.68\n",
      "root_mean_squared_error          :  4.62\n",
      "mean_absolute_percentage_error   :  0.15\n"
     ]
    }
   ],
   "source": [
    "METRICS = {\n",
    "    \"r2_score\": lambda true, pred: r2_score(true, pred),\n",
    "    \"max_error\": lambda true, pred: max_error(true, pred),\n",
    "    \"mean_absolute_error\": lambda true, pred: mean_absolute_error(true, pred),\n",
    "    \"root_mean_squared_error\": lambda true, pred: mean_squared_error(true, pred) ** 0.5,\n",
    "    \"mean_absolute_percentage_error\": lambda true, pred: mean_absolute_percentage_error(true, pred)\n",
    "}\n",
    "for key in METRICS.keys():\n",
    "    print(\"{:33}: {:5.2f}\".format(key, METRICS[key](ytest, ypred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2646b853ad16a06ac6e498ae25d59a5fce5123f2844d0bc5cb2cb740ffe879c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
